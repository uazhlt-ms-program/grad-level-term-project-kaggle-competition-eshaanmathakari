{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "def read_csv(file_path):\n",
    "    text_data = pd.read_csv(file_path, sep=\",\")\n",
    "    return text_data\n",
    "\n",
    "train_path = \"./data/train.csv\"\n",
    "test_path = \"./data/test.csv\"\n",
    "\n",
    "train_data = read_csv(train_path)\n",
    "test_data = read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         ID  \\\n",
      "0       7850790573542594519   \n",
      "1       9392069522632994700   \n",
      "2       5083704536542443514   \n",
      "3      12418349755186772171   \n",
      "4      12144957944004619479   \n",
      "...                     ...   \n",
      "70312   4533411613007495120   \n",
      "70313   2075555016956547354   \n",
      "70314   5446360756235190232   \n",
      "70315  11502529898454172361   \n",
      "70316  11352924827579021872   \n",
      "\n",
      "                                                    TEXT  LABEL  \n",
      "0      If you love good films don't ever buy this pei...      2  \n",
      "1      The 33 percent of the nations nitwits that sti...      2  \n",
      "2      I saw Anatomy years ago -- dubbed at a friends...      1  \n",
      "3      Dark Remains is a home run plain and simple. T...      1  \n",
      "4      Feh. This movie started out in an interesting ...      2  \n",
      "...                                                  ...    ...  \n",
      "70312  I grew up looking for fairies in my backyard, ...      0  \n",
      "70313  Jeff King,a guy I know from work,LOVES this Mo...      2  \n",
      "70314  I love the way Inder writes this story. Honest...      0  \n",
      "70315  I watched this movie recently and fell in love...      1  \n",
      "70316  491. Из 9 фунтов муки испечено 16 белых хлебов...      0  \n",
      "\n",
      "[70317 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         ID                                               TEXT\n",
      "0       4728459160322025755  An excellent debut movie for the the director ...\n",
      "1       1840432070229003467  If you have a preschooler or remember how stre...\n",
      "2      12623336783082722606  What should have been a routine babysitting gi...\n",
      "3       7446733850828603409                                           Cute but\n",
      "4      16180660281866613068  Elvis Presley plays a \"half-breed\" Native Amer...\n",
      "...                     ...                                                ...\n",
      "17575  15460118162570972562  I hardly ever write reviews here, but when thi...\n",
      "17576   2679547768967862209  　　\\n\\n三藏聞言，頂禮不盡。教：「徒弟們，收拾去罷。」那沙僧即在裏面尋了些米 糧，安排了...\n",
      "17577   2966026531113989116  Another winner by Faith Hunter....It's a wild,...\n",
      "17578  10698695044532313190  My students of all ages can't get enough of ac...\n",
      "17579   8504104014180128164  ...On stage, TV or in a book, 'The Woman in Bl...\n",
      "\n",
      "[17580 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN values in the 'TEXT' column\n",
    "train_data = train_data.dropna(subset=['TEXT'])\n",
    "# test_data = test_data['TEXT'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 17580 entries, 0 to 17579\n",
      "Series name: TEXT\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "17580 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 137.5+ KB\n",
      "None\n",
      "object\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Print general information about the DataFrame\n",
    "print(test_data.info())  \n",
    "\n",
    "# Print the data types of all columns\n",
    "print(test_data.dtypes) \n",
    "\n",
    "# # Print unique values in the 'LABEL' column\n",
    "# print(test_data['LABEL'].unique()) \n",
    "\n",
    "# Check for missing values\n",
    "print(test_data.isna().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train_data['TEXT'])\n",
    "y_train = train_data['LABEL']\n",
    "X_test = vectorizer.transform(test_data['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "y_pred_val = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "val_f1 = f1_score(y_val, y_pred_val, average='macro')\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1-Score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'ID': test_data['ID'], 'LABEL': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if the submission dataframe has exactly 17580 rows\n",
    "# if len(submission_df) != 17580:\n",
    "#     print(\"Error: The submission dataframe does not have exactly 17580 rows.\")\n",
    "# else:\n",
    "#     # Save the submission dataframe as a CSV file\n",
    "#     submission_df.to_csv('./data/submission/submission.csv', index=False)\n",
    "#     print(\"Submission file saved successfully.\")\n",
    "# Create submission file without 'LABEL' column (if submission is still expected)\n",
    "submission_df = pd.DataFrame({'ID': test_data['ID'], 'LABEL': y_pred})\n",
    "submission_df.to_csv('./data/submission/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print general information about the DataFrame\n",
    "print(submission_df.info())  \n",
    "\n",
    "# Print the data types of all columns\n",
    "print(submission_df.dtypes) \n",
    "\n",
    "# Print unique values in the 'LABEL' column\n",
    "print(submission_df['LABEL'].unique()) \n",
    "\n",
    "# Check for missing values\n",
    "print(submission_df.isna().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Text preprocessing function\n",
    "# def preprocess_text(text):\n",
    "#     processed_text = text.lower()\n",
    "#     processed_text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))', '<URL>', processed_text)\n",
    "#     processed_text = re.sub(r'\\d+', '<PHONE>', processed_text)\n",
    "#     processed_text = re.sub(r'[^a-zA-Z\\s]', '', processed_text)\n",
    "#     processed_text = re.sub(r'[^\\w\\s]', '<PUNCT>', processed_text)\n",
    "#     processed_text = re.sub(r'\\b\\w\\b', '<SNGL>', processed_text)\n",
    "#     processed_text = re.sub(r'\\s+', '<SPC>', processed_text).strip()\n",
    "    \n",
    "#     return processed_text\n",
    "\n",
    "# # Preprocess text data\n",
    "# train_data['TEXT'] = train_data['TEXT'].astype('str').apply(preprocess_text)\n",
    "# test_data['TEXT'] = test_data['TEXT'].astype('str').apply(preprocess_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
